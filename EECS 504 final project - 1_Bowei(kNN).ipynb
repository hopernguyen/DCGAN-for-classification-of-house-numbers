{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EECS 504 final project - 1_Bowei(kNN).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hu4KFlFWgbXx"},"source":["Install required libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6qwOZFJIB7H","executionInfo":{"status":"ok","timestamp":1618879790372,"user_tz":240,"elapsed":20387,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}},"outputId":"7a25dab8-173b-4e19-a50a-fc5021445759"},"source":["!pip install wandb\n","!pip install -U scikit-learn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/28/4aefc543967839bdb4e139831b82004279f1c435cede2a9557ccf8369875/wandb-0.10.27-py2.py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 7.1MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 34.6MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 29.8MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: pathtools, subprocess32\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=b55f71677283d0c476f8dd591a6968eb660397d4d5b846feea590a9ab2f7ca13\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=ccc075bd340de5edb664098d6eac30382613d93e1941b0a05cbcded8df4d67da\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","Successfully built pathtools subprocess32\n","Installing collected packages: pathtools, subprocess32, shortuuid, smmap, gitdb, GitPython, docker-pycreds, configparser, sentry-sdk, wandb\n","Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.27\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_P8r7T-TOk7q"},"source":["Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhGsrzxUOKSI","executionInfo":{"status":"ok","timestamp":1618879812932,"user_tz":240,"elapsed":19487,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}},"outputId":"934122f5-f3e8-4599-c6a0-57e29f040995"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C39mflS_Ou0a"},"source":["Import libraries"]},{"cell_type":"code","metadata":{"id":"B1MU-18SOwPC","executionInfo":{"status":"ok","timestamp":1618879833047,"user_tz":240,"elapsed":3941,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}}},"source":["import os\n","import sys\n","import torch\n","import torchvision\n","from torchvision import transforms, datasets\n","import numpy as np\n","import sklearn\n","from sklearn.neighbors import KNeighborsClassifier\n","# import wandb #Import this to collab\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import torchvision.utils as vutils\n","import torch.nn as nn\n","import torch.optim as optim\n","#from config import config\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from sklearn.metrics import accuracy_score\n","# import torchgan\n","# from torchgan.layers import SpectralNorm2d\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhRXvNDRO5_b","executionInfo":{"status":"ok","timestamp":1618838027121,"user_tz":240,"elapsed":45847,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"}},"outputId":"8dcd146e-8240-4392-806c-9baaaab2d3ed"},"source":["# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(\"Using the GPU!\")\n","else:\n","    print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bf1xmI8AOofy"},"source":["Load images"]},{"cell_type":"code","metadata":{"id":"82-1omlZOqHy","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1618878326822,"user_tz":240,"elapsed":84637,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"85f8b308-a2d8-4f11-982b-3ddfec234b4a"},"source":["# Import from our Shared Google Drive\n","# Set directories for training and testing datasets\n","\n","digits = range(1,11)\n","\n","# Images are 32 x 32\n","img_size = 32\n","image_size = 32\n","\n","# Create transforms\n","train_transform = transforms.Compose([\n","    transforms.Resize(img_size),\n","    transforms.CenterCrop(img_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.Resize(img_size),\n","    transforms.CenterCrop(img_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n","\n","# main_dir = \"/content/drive/Shareddrives/EECS 504 Shared Drive/Fake Images/\"\n","\n","# Load all 128 images\n","Create datasets\n","# generated_images = datasets.ImageFolder(main_dir, transform=train_transform)\n","# test_img = datasets.ImageFolder(test_dir, transform=test_transform) \n","\n","# root_dir = \"/content/drive/Shareddrives/EECS 504 Shared Drive/Datasets/SVHN Dataset/\"\n","\n","# train_dir = root_dir + \"train/\"\n","# train_img = datasets.ImageFolder(train_dir, transform=train_transform) \n","\n","# test_dir = root_dir + \"test/\"\n","# test_img = datasets.ImageFolder(test_dir, transform=test_transform) \n","\n","# main_dir = \"/content/drive/Shareddrives/EECS 504 Shared Drive/Fake Images/\"\n","# generated_images = datasets.ImageFolder(main_dir, transform=train_transform)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-6ee66964ac9c>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    Create datasets\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FlGeuR6RySg","executionInfo":{"status":"ok","timestamp":1618838496528,"user_tz":240,"elapsed":515248,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"}},"outputId":"e4b3c3b8-9438-4d45-9b2d-d600e3597e8e"},"source":["print(\"train_img type   :\",type(train_img))\n","print(\"train_img length :\",len(train_img))\n","print(\"train_img classes:\",train_img.classes)\n","print(\"train_img[0] type:\",type(train_img[0]))\n","print(\"train_img[0][0] t:\",type(train_img[0][0]))\n","print(\"train_img[0][1] t:\",type(train_img[0][1]))\n","print(\"train_img[0][0] s:\",train_img[0][0].size())\n","print(\"train_img[0][1]  :\",train_img[0][1])\n","\n","n_labels = len(train_img.classes)\n","\n","print(\"test_img type   :\",type(test_img))\n","print(\"test_img length :\",len(test_img))\n","print(\"test_img classes:\",test_img.classes)\n","print(\"test_img[0] type:\",type(test_img[0]))\n","print(\"test_img[0][0] t:\",type(test_img[0][0]))\n","print(\"test_img[0][1] t:\",type(test_img[0][1]))\n","print(\"test_img[0][0] s:\",test_img[0][0].size())\n","print(\"test_img[0][1]  :\",test_img[0][1])\n","\n","print(\"generated_images type   :\",type(generated_images))\n","print(\"generated_images length :\",len(generated_images))\n","# print(\"test_img length :\",len(test_img))\n","print(\"generated_images classes:\",generated_images.classes)\n","print(\"generated_images[0] type:\",type(generated_images[0]))\n","print(\"generated_images[0][0] t:\",type(generated_images[0][0]))\n","print(\"generated_images[0][1] t:\",type(generated_images[0][1]))\n","print(\"generated_images[0][0] s:\",generated_images[0][0].size())\n","print(\"generated_images[0][1]  :\",generated_images[0][1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_img type   : <class 'torchvision.datasets.folder.ImageFolder'>\n","train_img length : 42617\n","train_img classes: ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","train_img[0] type: <class 'tuple'>\n","train_img[0][0] t: <class 'torch.Tensor'>\n","train_img[0][1] t: <class 'int'>\n","train_img[0][0] s: torch.Size([3, 32, 32])\n","train_img[0][1]  : 0\n","test_img type   : <class 'torchvision.datasets.folder.ImageFolder'>\n","test_img length : 25982\n","test_img classes: ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","test_img[0] type: <class 'tuple'>\n","test_img[0][0] t: <class 'torch.Tensor'>\n","test_img[0][1] t: <class 'int'>\n","test_img[0][0] s: torch.Size([3, 32, 32])\n","test_img[0][1]  : 0\n","generated_images type   : <class 'torchvision.datasets.folder.ImageFolder'>\n","generated_images length : 23006\n","generated_images classes: ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","generated_images[0] type: <class 'tuple'>\n","generated_images[0][0] t: <class 'torch.Tensor'>\n","generated_images[0][1] t: <class 'int'>\n","generated_images[0][0] s: torch.Size([3, 32, 32])\n","generated_images[0][1]  : 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GmxgXwgOBBQ2"},"source":["# Classification (K Nearest Neighbors)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_-BhkahOYZy-"},"source":["Be sure to run everything before and including \"Loading Data\" part"]},{"cell_type":"markdown","metadata":{"id":"8Gv4Dt3YveG1"},"source":["Image processing"]},{"cell_type":"code","metadata":{"id":"B-6D0CAzvYv8"},"source":["def knn_image_proc(data_img, m = None):\n","  '''\n","  Image flattening and normalization for kNN\n","  Input:\n","    data_img: images and labels\n","  Output:\n","    x_train: processed images (flattened to be vectors and normalized)\n","    y: labels\n","  '''\n","  n_train = len(data_img)\n","\n","  x_raw = []\n","\n","  y = []\n","\n","  for i in range(n_train):\n","    # x_i = train_img[i][0].reshape(-1)\n","    x_i = np.array(data_img[i][0].reshape(-1))\n","    x_raw.append(x_i)\n","    y.append(data_img[i][1])\n","\n","    if i%1000 == 0:\n","      print('Has processed ' + str(i) + ' out of ' + str(n_train) + ' images')\n","\n","  # Normalize to zero mean so covariance is just matrix multiplication\n","  if m is None: \n","    m = np.mean(x_raw, axis=0, keepdims=True)\n","  x = x_raw - m \n","\n","  return x, y,  m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trZusXQLvjVz"},"source":["Reduction"]},{"cell_type":"code","metadata":{"id":"WKVEvZZCtjmm"},"source":["def compute_basis(data, n=300):\n","  \"\"\" \n","  Computing basis for image reduction\n","  Inputs:\n","      data: multi-dimensional array of size number of images * number of pixels. Each row is a flatten image.\n","      n: number of modes to be kept\n","  Output:\n","      eigenvectors: basis\n","  \"\"\"\n","  \n","  eigenvectors = None\n","\n","  sig = np.matmul(np.transpose(data),data)\n","  _, eigenvectors = np.linalg.eig(sig)\n","  eigenvectors = eigenvectors[:, range(n)]\n","\n","  return eigenvectors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Id3c1RB2vp3n"},"source":["kNN"]},{"cell_type":"code","metadata":{"id":"KQvR_PCLqg-d"},"source":["# # Self defined kNN function\n","# def knn_predict(eig_train_x, eig_test_x, y_train, y_test, k=1):\n","\n","#   \"\"\"Implement the KNN algorithm. The output should be a vector containing your predictions\"\"\"\n","\n","#   predictions = np.zeros_like(y_test)\n","    \n","#   N, D = eig_train_x.shape\n","#   for i in range(len(y_test)):\n","#     d = np.ones((N,))\n","#     for j in range(N):\n","#       dx = eig_train_x[j,:] - eig_test_x[i,:]\n","#       d[j] = np.linalg.norm(dx)\n","\n","#     x_in = np.argsort(d)\n","#     neb_in = x_in[:k]\n","#     neb_y = y_train[neb_in]\n","\n","#     counts = np.bincount(neb_y)\n","#     predictions[i] = np.argmax(counts)\n","\n","#   return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPc9UwJgSK4e"},"source":["# kNN over the original data set (real image)"]},{"cell_type":"code","metadata":{"id":"iL7pUsdPAryr"},"source":["# Data will be saved to here\n","save_dir = '/content/drive/Shareddrives/EECS 504 Shared Drive/Dictionary Saved/'\n","\n","k = 10 # k nearest neighbors\n","\n","if_POD = True # Do we do POD?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2lAn79IPdUz","executionInfo":{"elapsed":19888350,"status":"ok","timestamp":1618776883421,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"},"user_tz":240},"outputId":"a46bba74-67b5-4ccf-a051-5f333537a2bf"},"source":["\n","# Image flattening and normalization for the original training data set\n","# x_train_real, y_train_real, mean_train_real = knn_image_proc(train_img)\n","\n","# Image reduction\n","if if_POD:\n","  eigenvectors_real = compute_basis(x_train_real, n=300)\n","else:\n","  _, n_dim  = x_train_real.shape\n","  eigenvectors_real = np.identity(n_dim)\n","\n","x_train_reduced_real = np.matmul(x_train_real, eigenvectors_real)\n","\n","# kNN training\n","neigh_real = KNeighborsClassifier(n_neighbors = k)\n","neigh_real.fit(x_train_reduced_real, y_train_real)\n","\n","# save_dict_real = {\"x_train_real\":x_train_real, \n","#              \"y_train_real\":y_train_real, \n","#              \"mean_train_real\":mean_train_real,\n","#              \"neigh_real\":neigh_real}\n","\n","# np.save(save_dir + 'save_dict_real.npy', save_dict_real)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Has processed 0 out of 42617 images\n","Has processed 1000 out of 42617 images\n","Has processed 2000 out of 42617 images\n","Has processed 3000 out of 42617 images\n","Has processed 4000 out of 42617 images\n","Has processed 5000 out of 42617 images\n","Has processed 6000 out of 42617 images\n","Has processed 7000 out of 42617 images\n","Has processed 8000 out of 42617 images\n","Has processed 9000 out of 42617 images\n","Has processed 10000 out of 42617 images\n","Has processed 11000 out of 42617 images\n","Has processed 12000 out of 42617 images\n","Has processed 13000 out of 42617 images\n","Has processed 14000 out of 42617 images\n","Has processed 15000 out of 42617 images\n","Has processed 16000 out of 42617 images\n","Has processed 17000 out of 42617 images\n","Has processed 18000 out of 42617 images\n","Has processed 19000 out of 42617 images\n","Has processed 20000 out of 42617 images\n","Has processed 21000 out of 42617 images\n","Has processed 22000 out of 42617 images\n","Has processed 23000 out of 42617 images\n","Has processed 24000 out of 42617 images\n","Has processed 25000 out of 42617 images\n","Has processed 26000 out of 42617 images\n","Has processed 27000 out of 42617 images\n","Has processed 28000 out of 42617 images\n","Has processed 29000 out of 42617 images\n","Has processed 30000 out of 42617 images\n","Has processed 31000 out of 42617 images\n","Has processed 32000 out of 42617 images\n","Has processed 33000 out of 42617 images\n","Has processed 34000 out of 42617 images\n","Has processed 35000 out of 42617 images\n","Has processed 36000 out of 42617 images\n","Has processed 37000 out of 42617 images\n","Has processed 38000 out of 42617 images\n","Has processed 39000 out of 42617 images\n","Has processed 40000 out of 42617 images\n","Has processed 41000 out of 42617 images\n","Has processed 42000 out of 42617 images\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier()"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"VAJPFiNBuIo1","executionInfo":{"status":"error","timestamp":1618879224096,"user_tz":240,"elapsed":362,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"fdc56c5d-ebac-4315-c00f-234ba7a48996"},"source":["# kNN training\n","neigh_real = KNeighborsClassifier(n_neighbors = k)\n","neigh_real.fit(x_train_reduced_real, y_train_real)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-86c5ddbf34a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# kNN training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mneigh_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mneigh_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_reduced_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_train_reduced_real' is not defined"]}]},{"cell_type":"code","metadata":{"id":"3SdM5HmoB8Bg"},"source":["# Image flattening and normalization for the original test data set\n","# x_test_real, y_test_, _ = knn_image_proc(test_img, mean_train_real)\n","y_test = np.array(y_test_)\n","\n","x_test_real_reduced = np.matmul(x_test_real, eigenvectors_real)\n","\n","# kNN prediction\n","y_test_real_kNN = neigh_real.predict(x_test_real_reduced)\n","\n","## Evalution\n","accuracy_real = np.sum(y_test_real_kNN == y_test)/y_test_real_kNN.size\n","print('The accuracy of kNN with real images is: ', accuracy_real*100, \"%\")\n","\n","accuracy_real_digit = zeros(1, n_labels)\n","print('Accuracy for individual digits:')\n","for i_digit in range(1,n_labels+1):\n","  y_test_digit = y_test[y_test==i_digit]\n","  accuracy_real_digit[i_digit-1] = np.sum(y_test_kNN_real[y_test==i_digit] == y_test_digit)/y_test_digit.size\n","  print('The accuracy of kNN with real images ' + 'for digit ', i_digit, 'is: ', accuracy_real_digit[i_digit-1]*100, \"%\")\n","\n","df = pd.DataFrame({'lab':str(range(1,n_labels+1)), 'val':accuracy_real_digit*100})\n","ax = df.plot.bar(x='Digits', y='Accuracy (%)', rot=0)\n","\n","save_dict_real = {\"x_train_real\":x_train_real, \n","             \"y_train_real\":y_train_real,\n","             \"x_test_real\":x_test_real,\n","             \"y_test\":y_test,\n","             \"mean_train_real\":mean_train_real,\n","             \"neigh_real\":neigh_real,\n","             \"accuracy_real\":accuracy_real,\n","             \"accuracy_real_digit\":accuracy_real_digit}\n","\n","np.save(save_dir + 'save_dict_real.npy', save_dict_real)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fejIjQ6RJhJ"},"source":["# kNN over generated data set (generated images)"]},{"cell_type":"code","metadata":{"id":"rnBV_k24RRPR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618875681554,"user_tz":240,"elapsed":144057,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"}},"outputId":"0a7aa61c-85a6-432a-b5bf-d687db4f73e5"},"source":["# Image flattening and normalization for the original training data set\n","x_train_fake, y_train_fake, mean_train_fake = knn_image_proc(generated_images)\n","\n","# Image reduction\n","if if_POD:\n","  eigenvectors_fake = compute_basis(x_train_fake, n=300)\n","else:\n","  _, n_dim  = x_train_fake.shape\n","  eigenvectors_fake = np.identity(n_dim)\n","\n","x_train_fake_reduced = np.matmul(x_train_fake, eigenvectors_fake)\n","\n","# kNN training\n","neigh_fake = KNeighborsClassifier(n_neighbors = k)\n","neigh_fake.fit(x_train_fake_reduced, y_train_fake)\n","\n","save_dict_fake = {\"x_train_fake\":x_train_fake, \n","             \"y_train_fake\":y_train_fake,\n","             \"mean_train_fake\":mean_train_fake,\n","             \"neigh_fake\":neigh_fake\n","             }\n","\n","np.save(save_dir + 'save_dict_fake.npy', save_dict_fake)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Has processed 0 out of 23006 images\n","Has processed 1000 out of 23006 images\n","Has processed 2000 out of 23006 images\n","Has processed 3000 out of 23006 images\n","Has processed 4000 out of 23006 images\n","Has processed 5000 out of 23006 images\n","Has processed 6000 out of 23006 images\n","Has processed 7000 out of 23006 images\n","Has processed 8000 out of 23006 images\n","Has processed 9000 out of 23006 images\n","Has processed 10000 out of 23006 images\n","Has processed 11000 out of 23006 images\n","Has processed 12000 out of 23006 images\n","Has processed 13000 out of 23006 images\n","Has processed 14000 out of 23006 images\n","Has processed 15000 out of 23006 images\n","Has processed 16000 out of 23006 images\n","Has processed 17000 out of 23006 images\n","Has processed 18000 out of 23006 images\n","Has processed 19000 out of 23006 images\n","Has processed 20000 out of 23006 images\n","Has processed 21000 out of 23006 images\n","Has processed 22000 out of 23006 images\n","Has processed 23000 out of 23006 images\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mcnVGybaRs_S","colab":{"base_uri":"https://localhost:8080/","height":703},"executionInfo":{"status":"error","timestamp":1618877790690,"user_tz":240,"elapsed":170686,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"}},"outputId":"72e1b939-4a5e-4df9-87ac-d59c8095846e"},"source":["# Image flattening and normalization for the original test data set\n","x_test_fake, _, _ = knn_image_proc(test_img, mean_train_fake)\n","\n","x_test_fake_reduced = np.matmul(x_test_fake, eigenvectors_fake)\n","\n","# kNN prediction\n","y_test_fake_kNN = neigh_fake.predict(x_test_fake_reduced)\n","\n","## Evalution\n","accuracy_fake = np.sum(y_test_fake_kNN == y_test)/y_test_fake_kNN.size\n","print('The accuracy of kNN with the original and generated images is: ', accuracy_fake*100, \"%\")\n","\n","accuracy_fake_digit = zeros(1, n_labels)\n","print('Accuracy for individual digits:')\n","for i_digit in range(1,n_labels+1):\n","  y_test_digit = y_test[y_test==i_digit]\n","  accuracy_fake_digit[i_digit-1] = np.sum(y_test_fake_kNN[y_test==i_digit] == y_test_digit)/y_test_digit.size\n","  print('The accuracy of kNN with the generated images ' + 'for digit ', i_digit, 'is: ', accuracy_fake_digit[i_digit-1]*100, \"%\")\n","\n","df = pd.DataFrame({'lab':str(range(1,n_labels+1)), 'val':accuracy_fake_digit})\n","ax = df.plot.bar(x='Digits', y='Accuracy (%)', rot=0)\n","\n","save_dict_fake = {\"x_train_fake\":x_train_fake, \n","             \"y_train_fake\":y_train_fake,\n","             \"x_test_fake\":x_test_fake,\n","             \"y_test\":y_test,\n","             \"mean_train_fake\":mean_train_fake,\n","             \"neigh_fake\":neigh_fake,\n","             \"accuracy_fake\":accuracy_fake,\n","             \"accuracy_fake_digit\":accuracy_fake_digit,\n","             }\n","\n","np.save(save_dir + 'save_dict_fake.npy', save_dict_fake)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Has processed 0 out of 25982 images\n","Has processed 1000 out of 25982 images\n","Has processed 2000 out of 25982 images\n","Has processed 3000 out of 25982 images\n","Has processed 4000 out of 25982 images\n","Has processed 5000 out of 25982 images\n","Has processed 6000 out of 25982 images\n","Has processed 7000 out of 25982 images\n","Has processed 8000 out of 25982 images\n","Has processed 9000 out of 25982 images\n","Has processed 10000 out of 25982 images\n","Has processed 11000 out of 25982 images\n","Has processed 12000 out of 25982 images\n","Has processed 13000 out of 25982 images\n","Has processed 14000 out of 25982 images\n","Has processed 15000 out of 25982 images\n","Has processed 16000 out of 25982 images\n","Has processed 17000 out of 25982 images\n","Has processed 18000 out of 25982 images\n","Has processed 19000 out of 25982 images\n","Has processed 20000 out of 25982 images\n","Has processed 21000 out of 25982 images\n","Has processed 22000 out of 25982 images\n","Has processed 23000 out of 25982 images\n","Has processed 24000 out of 25982 images\n","Has processed 25000 out of 25982 images\n","The accuracy of kNN with the original and generated images is:  20.89523516280502 %\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-38a2d3ead4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The accuracy of kNN with the original and generated images is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_fake\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0maccuracy_fake_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy for individual digits:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_digit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'zeros' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"PHDl9TqEjBpn"},"source":["# kNN over combined data set (real and generated images)"]},{"cell_type":"code","metadata":{"id":"9y26sA22lC4w"},"source":["# img_sets = [];\n","# img_sets.append(train_img)\n","# img_sets.append(generated_images)\n","# image_datasets = torch.utils.data.ConcatDataset(img_sets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZflrkLs0Ek30"},"source":["save_dict_comb = {\"x_train_comb\":x_train_comb,\n","                  \"y_train_comb\":y_train_comb,\n","                  \"mean_train_comb\":mean_train_comb,\n","                  \"neigh_comb\":neigh_comb,\n","                  \"x_train_comb_reduced\": x_train_comb_reduced}\n","\n","np.save(save_dir + 'save_dict_comb.npy', save_dict_comb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyoYyqn2l8C_","executionInfo":{"status":"ok","timestamp":1618879906022,"user_tz":240,"elapsed":3029,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}},"outputId":"bd03ac51-3f65-4097-c624-f5556b7fbedc"},"source":["# Image flattening and normalization for the original training data set\n","# x_train_comb, y_train_comb, mean_train_comb = knn_image_proc(image_datasets)\n","k = 10\n","\n","load_dictionary = np.load('/content/drive/Shareddrives/EECS 504 Shared Drive/Dictionary Saved/save_dict_comb.npy',allow_pickle='TRUE').item()\n","x_train_comb = load_dictionary['x_train_comb']\n","y_train_comb = load_dictionary['y_train_comb']\n","x_train_comb_reduced = load_dictionary['x_train_comb_reduced']\n","# Image reduction\n","# if if_POD:\n","#   eigenvectors_comb = compute_basis(x_train_comb, n=300)\n","# else:\n","#   _, n_dim  = x_train_comb.shape\n","#   eigenvectors_comb = np.identity(n_dim)\n","\n","# x_train_comb_reduced = np.matmul(x_train_comb, eigenvectors_comb)\n","\n","# kNN training\n","neigh_comb = KNeighborsClassifier(n_neighbors = k)\n","neigh_comb.fit(x_train_comb_reduced, y_train_comb)\n","\n","# save_dict_comb = {\"x_train_comb\":x_train_comb,\n","#                   \"y_train_comb\":y_train_comb,\n","#                   \"mean_train_comb\":mean_train_comb,\n","#                   \"neigh_comb\":neigh_comb}\n","\n","# np.save(save_dir + 'save_dict_comb.npy', save_dict_comb)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(n_neighbors=10)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU-rnw-muWWp","executionInfo":{"status":"ok","timestamp":1618879280534,"user_tz":240,"elapsed":448,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"c195a15d-35bf-41ca-8aa4-78b44e6b0e89"},"source":["# kNN training\n","neigh_comb = KNeighborsClassifier(n_neighbors = k)\n","neigh_comb.fit(x_train_comb_reduced, y_train_comb)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(n_neighbors=10)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"VgViiklOmcbl","colab":{"base_uri":"https://localhost:8080/","height":516},"executionInfo":{"status":"ok","timestamp":1618880499154,"user_tz":240,"elapsed":69107,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}},"outputId":"19b04701-3cc7-4ed7-f303-671f1502e11f"},"source":["# Image flattening and normalization for the original test data set\n","# x_test_comb, y_test, _ = knn_image_proc(test_img, mean_train_comb)\n","read_dictionary = np.load('/content/drive/Shareddrives/EECS 504 Shared Drive/Dictionary Saved/save_dict_comb.npy',allow_pickle='TRUE').item()\n","x_test_comb = read_dictionary['x_test_comb']\n","y_test_comb = read_dictionary['y_test']\n","x_test_comb_reduced = read_dictionary['x_test_comb_reduced']\n","\n","# x_test_comb_reduced = np.matmul(x_test_comb, eigenvectors_comb)\n","\n","# kNN prediction\n","y_test_comb_kNN = neigh_comb.predict(x_test_comb_reduced)\n","\n","## Evalution\n","accuracy_comb = np.sum(y_test_comb_kNN == y_test_comb)/y_test_comb_kNN.size\n","print('The accuracy of kNN with the original and generated images is: ', accuracy_comb*100, \"%\")\n","\n","n_labels = 10\n","y_test = np.array(y_test_comb)\n","accuracy_comb_digit = np.zeros((n_labels,))\n","print('Accuracy for individual digits:')\n","for i_digit in range(1,n_labels+1):\n","  evalu_digit = i_digit\n","  if i_digit == 10:\n","    evalu_digit = 0\n","  y_test_digit = y_test[y_test==evalu_digit]\n","  accuracy_comb_digit[i_digit-1] = np.sum(y_test_comb_kNN[y_test==evalu_digit] == y_test_digit)/y_test_digit.size\n","  print('The accuracy of kNN with the original and generated images ' + 'for digit ', evalu_digit, 'is: ', accuracy_comb_digit[i_digit-1]*100, \"%\")\n","\n","x = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n","# x = np.zeros((n_labels, 1))\n","accuracyList = accuracy_comb_digit.tolist()\n","print(type(accuracyList))\n","plt.bar(x, accuracyList)\n","plt.title('Accuracy of Each Digit - Generated & Real Dataset')\n","plt.xlabel('Digit #')\n","plt.ylabel('Correct Classifications')\n","plt.show()\n","\n","\n","# save_dict_comb = {\"x_train_comb\":x_train_comb,\n","#              \"y_train_comb\":y_train_comb,\n","#              \"x_test_comb\":x_test_comb,\n","#              \"y_test\":y_test,\n","#              \"mean_train_comb\":mean_train_comb,\n","#              \"neigh_comb\":neigh_comb,\n","#              \"accuracy_comb\":accuracy_comb,\n","#              \"accuracy_comb_digit\":accuracy_comb_digit}\n","\n","# np.save(save_dir + 'save_dict_comb.npy', save_dict_comb)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The accuracy of kNN with the original and generated images is:  55.54614733276884 %\n","Accuracy for individual digits:\n","The accuracy of kNN with the original and generated images for digit  1 is:  67.43119266055045 %\n","The accuracy of kNN with the original and generated images for digit  2 is:  54.08532176428055 %\n","The accuracy of kNN with the original and generated images for digit  3 is:  38.6884108258154 %\n","The accuracy of kNN with the original and generated images for digit  4 is:  70.0753071739992 %\n","The accuracy of kNN with the original and generated images for digit  5 is:  37.79362416107382 %\n","The accuracy of kNN with the original and generated images for digit  6 is:  43.14618108244815 %\n","The accuracy of kNN with the original and generated images for digit  7 is:  61.36701337295691 %\n","The accuracy of kNN with the original and generated images for digit  8 is:  35.722891566265055 %\n","The accuracy of kNN with the original and generated images for digit  9 is:  44.63949843260188 %\n","The accuracy of kNN with the original and generated images for digit  0 is:  75.87641117052881 %\n","<class 'list'>\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"c5u9I_6Bxnsy","executionInfo":{"status":"error","timestamp":1618880137196,"user_tz":240,"elapsed":267,"user":{"displayName":"Spencer Gable-Cook","photoUrl":"","userId":"09809321037722265364"}},"outputId":"80af1920-8b17-4683-90ca-2a6ed92ce556"},"source":["accuracy_comb = np.sum(y_test_comb_kNN == y_test_comb)/y_test_comb_kNN.size\n","print('The accuracy of kNN with the original and generated images is: ', accuracy_comb*100, \"%\")\n","\n","n_labels = 10\n","accuracy_comb_digit = np.zeros((n_labels,))\n","print('Accuracy for individual digits:')\n","for i_digit in range(1,n_labels+1):\n","  evalu_digit = i_digit\n","  if i_digit == 10:\n","    evalu_digit = 0\n","  y_test_digit = y_test_comb[y_test_comb==evalu_digit]\n","  accuracy_comb_digit[i_digit-1] = np.sum(y_test_comb_kNN[y_test_comb==evalu_digit] == y_test_digit)/y_test_digit.size\n","  print('The accuracy of kNN with the original and generated images ' + 'for digit ', evalu_digit, 'is: ', accuracy_comb_digit[i_digit-1]*100, \"%\")\n","\n","x = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n","# x = np.zeros((n_labels, 1))\n","accuracyList = accuracy_comb_digit.tolist()\n","print(type(accuracyList))\n","plt.bar(x, accuracyList)\n","plt.title('Accuracy of Each Digit - Generated & Real Dataset')\n","plt.xlabel('Digit #')\n","plt.ylabel('Correct Classifications')\n","plt.show()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["The accuracy of kNN with the original and generated images is:  55.54614733276884 %\n","Accuracy for individual digits:\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-753bc858817a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mevalu_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my_test_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_comb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_comb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevalu_digit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0maccuracy_comb_digit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_digit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_comb_kNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test_comb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevalu_digit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_test_digit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The accuracy of kNN with the original and generated images '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'for digit '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalu_digit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_comb_digit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_digit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_iNXWTxtqr8","executionInfo":{"status":"ok","timestamp":1618879368997,"user_tz":240,"elapsed":66484,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"9ca4f4af-3b93-4aa0-af89-36b660d48034"},"source":["y_test_comb_kNN = neigh_comb.predict(x_test_comb_reduced)\n","## Evalution\n","accuracy_comb = np.sum(y_test_comb_kNN == y_test_comb)/y_test_comb_kNN.size\n","print('The accuracy of kNN with the original and generated images is: ', accuracy_comb*100, \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The accuracy of kNN with the original and generated images is:  55.54614733276884 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LzGcetcPfkN_"},"source":["save_dict_comb = {\"x_train_comb\":x_train_comb,\n","             \"y_train_comb\":y_train_comb,\n","             \"x_train_comb_reduced\": x_train_comb_reduced,\n","             \"x_test_comb\":x_test_comb,\n","             \"y_test\":y_test,\n","             \"x_test_comb_reduced\": x_test_comb_reduced,\n","             \"mean_train_comb\":mean_train_comb,\n","             \"neigh_comb\":neigh_comb,\n","             \"accuracy_comb\":accuracy_comb,\n","              }\n","\n","np.save(save_dir + 'save_dict_comb.npy', save_dict_comb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"9A9BVHEYenBp","executionInfo":{"status":"error","timestamp":1618875263677,"user_tz":240,"elapsed":256,"user":{"displayName":"Bowei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9P9AtcBWeaiCdrWRJGvOYF2m1zAoBRoaTIWm78Q=s64","userId":"03011700941207122525"}},"outputId":"19425d2c-1abe-4abd-d5a6-53e8fc7df315"},"source":["accuracy_comb_digit = np.zeros((n_labels,))\n","print('Accuracy for individual digits:')\n","for i_digit in range(1,n_labels+1):\n","  evalu_digit = i_digit\n","  if i_digit == 10:\n","    evalu_digit = 0\n","  y_test_digit = y_test[y_test==evalu_digit]\n","  accuracy_comb_digit[i_digit-1] = np.sum(y_test_comb_kNN[y_test==evalu_digit] == y_test_digit)/len(y_test_digit)\n","  print('The accuracy of kNN with the original and generated images ' + 'for digit ', evalu_digit, 'is: ', accuracy_comb_digit[i_digit-1]*100, \"%\")\n","\n","save_dict_comb = {\"x_train_comb\":x_train_comb,\n","             \"y_train_comb\":y_train_comb,\n","             \"x_test_comb\":x_test_comb,\n","             \"y_test\":y_test,\n","             \"mean_train_comb\":mean_train_comb,\n","             \"neigh_comb\":neigh_comb,\n","             \"accuracy_comb\":accuracy_comb,\n","             \"accuracy_comb_digit\":accuracy_comb_digit}\n","\n","np.save(save_dir + 'save_dict_comb.npy', save_dict_comb)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy for individual digits:\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-c7fd5b073b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mevalu_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0my_test_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevalu_digit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0maccuracy_comb_digit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_digit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_comb_kNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevalu_digit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The accuracy of kNN with the original and generated images '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'for digit '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalu_digit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_comb_digit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_digit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"]}]},{"cell_type":"markdown","metadata":{"id":"3VTM8JuEXaeq"},"source":["# Save results (processed data, kNN clasifier, and accuracy results)"]},{"cell_type":"code","metadata":{"id":"7fInxDGYVnnF"},"source":["save_dict = {\"x_train_real\":x_train_real, \n","             \"y_train_real\":y_train_real,\n","             \"x_test_real\":x_test_real,\n","             \"y_test\":y_test,\n","             \"mean_train_real\":mean_train_real,\n","             \"neigh_real\":neigh_real,\n","             \"accuracy_real\":accuracy_real,\n","             \"accuracy_real_digit\":accuracy_real_digit,\n","             \"x_train_fake\":x_train_fake, \n","             \"y_train_fake\":y_train_fake,\n","             \"x_test_fake\":x_test_fake,\n","             \"mean_train_fake\":mean_train_fake,\n","             \"neigh_fake\":neigh_fake,\n","             \"accuracy_fake\":accuracy_fake,\n","             \"accuracy_fake_digit\":accuracy_fake_digit,\n","             \"x_train_comb\":x_train_comb,\n","             \"y_train_comb\":y_train_comb,\n","             \"x_test_comb\":x_test_comb,\n","             \"mean_train_comb\":mean_train_comb,\n","             \"neigh_comb\":neigh_comb,\n","             \"accuracy_comb\":accuracy_comb,\n","             \"accuracy_comb_digit\":accuracy_comb_digit}\n","\n","np.save(save_dir + 'save_dict.npy', save_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkAHgGtIsVaZ"},"source":["# Class visualizations\n","Maaten, Laurens van der, and Geoffrey Hinton. \"Visualizing data using t-SNE.\" Journal of machine learning research 9.Nov (2008): 2579-2605.\n","http://www.cs.toronto.edu/~hinton/absps/tsnefinal.pdf\n","\n","https://github.com/mxl1990/tsne-pytorch/blob/master/tsne_torch.py\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"]},{"cell_type":"code","metadata":{"id":"JfXXLtkpsbMC"},"source":["import numpy as np\n","import matplotlib.pyplot as pyplot\n","import torch\n","from sklearn.cluster import KMeans\n","\n","class tsne_visual(object):\n","  def __init__(self, X, num_dims=2, initial_dims=50, perplexity=30.0):\n","    self.X = X # Input data, N x D array\n","    self.num_dims = num_dims # Number of dimensions after reduction, scalar\n","    self.initial_dims = initial_dims # Number of dimensions before reduction, scalar\n","    self.perplexity = perplexity # Perplexity for tSNE parameter search, scalar\n","\n","  def Hbeta_torch(self, D, beta=1.0):\n","    P = torch.exp(-D.clone() * beta)\n","\n","    sumP = torch.sum(P)\n","\n","    H = torch.log(sumP) + beta * torch.sum(D * P) / sumP\n","    P = P / sumP\n","\n","    return H, P\n","\n","  def x2p_torch(self, tol=1e-5):\n","    \"\"\"\n","        Performs a binary search to get P-values in such a way that each\n","        conditional Gaussian has the same perplexity.\n","    \"\"\"\n","    X = self.X # Input data, N x D array\n","    perplexity = self.perplexity # Perplexity for tSNE parameter search, scalar\n","\n","    # Initialize some variables\n","    print(\"Computing pairwise distances...\")\n","    (n, d) = X.shape\n","\n","    sum_X = torch.sum(X*X, 1)\n","    D = torch.add(torch.add(-2 * torch.mm(X, X.t()), sum_X).t(), sum_X)\n","\n","    P = torch.zeros(n, n)\n","    beta = torch.ones(n, 1)\n","    logU = torch.log(torch.tensor([perplexity]))\n","    n_list = [i for i in range(n)]\n","\n","    # Loop over all datapoints\n","    for i in range(n):\n","\n","        # Print progress\n","        if i % 500 == 0:\n","            print(\"Computing P-values for point %d of %d...\" % (i, n))\n","\n","        # Compute the Gaussian kernel and entropy for the current precision\n","        # there may be something wrong with this setting None\n","        betamin = None\n","        betamax = None\n","        Di = D[i, n_list[0:i]+n_list[i+1:n]]\n","\n","        (H, thisP) = self.Hbeta_torch(Di, beta[i])\n","\n","        # Evaluate whether the perplexity is within tolerance\n","        Hdiff = H - logU\n","        tries = 0\n","        while torch.abs(Hdiff) > tol and tries < 50:\n","\n","            # If not, increase or decrease precision\n","            if Hdiff > 0:\n","                betamin = beta[i].clone()\n","                if betamax is None:\n","                    beta[i] = beta[i] * 2.\n","                else:\n","                    beta[i] = (beta[i] + betamax) / 2.\n","            else:\n","                betamax = beta[i].clone()\n","                if betamin is None:\n","                    beta[i] = beta[i] / 2.\n","                else:\n","                    beta[i] = (beta[i] + betamin) / 2.\n","\n","            # Recompute the values\n","            (H, thisP) = self.Hbeta_torch(Di, beta[i])\n","\n","            Hdiff = H - logU\n","            tries += 1\n","\n","        # Set the final row of P\n","        P[i, n_list[0:i]+n_list[i+1:n]] = thisP\n","\n","    # Return final P-matrix\n","    return P\n","\n","  def pca_torch(self):\n","\n","    X = self.X\n","    num_dims = self.initial_dims\n","\n","    print(\"Preprocessing the data using PCA...\")\n","    \n","    (n, d) = X.shape\n","    X = X - torch.mean(X, 0)\n","\n","    (l, M) = torch.eig(torch.mm(X.t(), X), True)\n","    # split M real\n","    for i in range(d):\n","        if l[i, 1] != 0:\n","            M[:, i+1] = M[:, i]\n","            i += 1\n","\n","    Y = torch.mm(X, M[:, 0:num_dims])\n","    return Y\n","\n","  def tsne(self):\n","    \"\"\"\n","        Runs t-SNE on the dataset in the N x D array X to reduce its\n","        dimensionality to num_dims dimensions. The syntaxis of the function is\n","        `Y = tsne.tsne(X, num_dims, perplexity), where X is an NxD NumPy array.\n","    \"\"\"\n","    X = self.X # Input data, N x D array\n","    num_dims = self.num_dims # Number of dimensions after reduction, scalar\n","\n","    # Check inputs\n","    if isinstance(num_dims, float):\n","        print(\"Error: array X should not have type float.\")\n","        return -1\n","    if round(num_dims) != num_dims:\n","        print(\"Error: number of dimensions should be an integer.\")\n","        return -1\n","\n","    # Initialize variables\n","    X = self.pca_torch()\n","    (n, d) = X.shape\n","    max_iter = 1000\n","    initial_momentum = 0.5\n","    final_momentum = 0.8\n","    eta = 500\n","    min_gain = 0.01\n","    Y = torch.randn(n, num_dims)\n","    dY = torch.zeros(n, num_dims)\n","    iY = torch.zeros(n, num_dims)\n","    gains = torch.ones(n, num_dims)\n","\n","    # Compute P-values\n","    P = self.x2p_torch(tol=1e-5)\n","    P = P + P.t()\n","    P = P / torch.sum(P)\n","    P = P * 4.    # early exaggeration\n","    print(\"get P shape\", P.shape)\n","    P = torch.max(P, torch.tensor([1e-21]))\n","\n","    # Run iterations\n","    for iter in range(max_iter):\n","\n","        # Compute pairwise affinities\n","        sum_Y = torch.sum(Y*Y, 1)\n","        num = -2. * torch.mm(Y, Y.t())\n","        num = 1. / (1. + torch.add(torch.add(num, sum_Y).t(), sum_Y))\n","        num[range(n), range(n)] = 0.\n","        Q = num / torch.sum(num)\n","        Q = torch.max(Q, torch.tensor([1e-12]))\n","\n","        # Compute gradient\n","        PQ = P - Q\n","        for i in range(n):\n","            dY[i, :] = torch.sum((PQ[:, i] * num[:, i]).repeat(num_dims, 1).t() * (Y[i, :] - Y), 0)\n","\n","        # Perform the update\n","        if iter < 20:\n","            momentum = initial_momentum\n","        else:\n","            momentum = final_momentum\n","\n","        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)).double() + (gains * 0.8) * ((dY > 0.) == (iY > 0.)).double()\n","        gains[gains < min_gain] = min_gain\n","        iY = momentum * iY - eta * (gains * dY)\n","        Y = Y + iY\n","        Y = Y - torch.mean(Y, 0)\n","\n","        # Compute current value of cost function\n","        if (iter + 1) % 10 == 0:\n","            C = torch.sum(P * torch.log(P / Q))\n","            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n","\n","        # Stop lying about P-values\n","        if iter == 100:\n","            P = P / 4.\n","        \n","        self.Y = Y # Data after dimension reduction\n","    # Return solution\n","    return Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pso8hyuqsb16"},"source":["# Post process Pareto set X\n","X = # Flattened image data \n","labels =  # digits\n","\n","digit_classes = tsne_visual(X, num_dims=2, initial_dims=50, perplexity=30.0)\n","Y = digit_classes.tsne() # Dimensionality reduction\n","\n","font_size = 18\n","pyplot.scatter(Y[:, 0], Y[:, 1], font_size, labels)\n","pyplot.xlabel('Space ')\n","# pyplot.ylabel('Latent policy parameter 2')\n","pyplot.rc('font', size=font_size)          # controls default text sizes\n","pyplot.rc('axes', titlesize=font_size)     # fontsize of the axes title\n","pyplot.rc('axes', labelsize=font_size)    # fontsize of the x and y labels\n","pyplot.rc('xtick', labelsize=font_size)\n","pyplot.rc('ytick', labelsize=font_size)\n","pyplot.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WB5xjHiZvs3v"},"source":["Visualization"]}]}