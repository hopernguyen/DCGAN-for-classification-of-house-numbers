{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":" EECS 504 final project - 1_Khoa(kNN).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hu4KFlFWgbXx"},"source":["Install required libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6qwOZFJIB7H","executionInfo":{"elapsed":21434,"status":"ok","timestamp":1618761651390,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"},"user_tz":240},"outputId":"9414d8b1-3228-4e43-d1d7-e08e60c4dd35"},"source":["!pip install wandb\n","!pip install -U scikit-learn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/5d/20ab24504de2669c9a76a50c9bdaeb44a440b0e5e4b92be881ed323857b1/wandb-0.10.26-py2.py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 18.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 18.7MB/s \n","\u001b[?25hCollecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n","Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.0MB/s \n","\u001b[?25hCollecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=025eb2c7acefce0161c31540271fb07e172ae7fcca11bb8ecfe6d122e454bf87\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=2e657f63e40aa73eabad20485d638761971c06266d5be230ce9fb929673b2195\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 pathtools\n","Installing collected packages: shortuuid, sentry-sdk, subprocess32, pathtools, docker-pycreds, smmap, gitdb, GitPython, configparser, wandb\n","Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.26\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 4.7MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_P8r7T-TOk7q"},"source":["Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhGsrzxUOKSI","executionInfo":{"elapsed":422663,"status":"ok","timestamp":1618762052633,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"},"user_tz":240},"outputId":"fb1e54c4-1d5e-4b53-e6e9-18763ee05cb7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C39mflS_Ou0a"},"source":["Import libraries"]},{"cell_type":"code","metadata":{"id":"B1MU-18SOwPC"},"source":["import os\n","import sys\n","import torch\n","import torchvision\n","from torchvision import transforms, datasets\n","import numpy as np\n","import sklearn\n","from sklearn.neighbors import KNeighborsClassifier\n","# import wandb #Import this to collab\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import torchvision.utils as vutils\n","import torch.nn as nn\n","import torch.optim as optim\n","#from config import config\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from sklearn.metrics import accuracy_score\n","# import torchgan\n","# from torchgan.layers import SpectralNorm2d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhRXvNDRO5_b","executionInfo":{"elapsed":426648,"status":"ok","timestamp":1618762056638,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"},"user_tz":240},"outputId":"351b1f59-4ce2-40c4-e7ed-bca40f352820"},"source":["# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(\"Using the GPU!\")\n","else:\n","    print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bf1xmI8AOofy"},"source":["Load images"]},{"cell_type":"code","metadata":{"id":"82-1omlZOqHy"},"source":["# Import from our Shared Google Drive\n","# Set directories for training and testing datasets\n","\n","digits = range(1,11)\n","\n","# Images are 32 x 32\n","img_size = 32\n","image_size = 32\n","\n","# Create transforms\n","train_transform = transforms.Compose([\n","    transforms.Resize(img_size),\n","    transforms.CenterCrop(img_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n","test_transform = transforms.Compose([\n","    transforms.Resize(img_size),\n","    transforms.CenterCrop(img_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n","\n","main_dir = \"/content/drive/Shareddrives/EECS 504 Shared Drive/Fake Images/\"\n","\n","# Load all 128 images\n","# Create datasets\n","generated_images = datasets.ImageFolder(main_dir, transform=train_transform)\n","# test_img = datasets.ImageFolder(test_dir, transform=test_transform) \n","\n","root_dir = \"/content/drive/Shareddrives/EECS 504 Shared Drive/Datasets/SVHN Dataset/\"\n","\n","#train_dir = root_dir + \"train/\"\n","#train_img = datasets.ImageFolder(train_dir, transform=train_transform) \n","\n","test_dir = root_dir + \"test/\"\n","test_img = datasets.ImageFolder(test_dir, transform=test_transform) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FlGeuR6RySg","executionInfo":{"elapsed":626806,"status":"ok","timestamp":1618762256810,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"},"user_tz":240},"outputId":"7c1179db-d1cf-49a3-d501-9fdaac302736"},"source":["# print(\"train_img type   :\",type(generated_images))\n","# print(\"train_img length :\",len(generated_images))\n","# # print(\"test_img length :\",len(test_img))\n","# print(\"train_img classes:\",generated_images.classes)\n","# print(\"train_img[0] type:\",type(generated_images[0]))\n","# print(\"train_img[0][0] t:\",type(generated_images[0][0]))\n","# print(\"train_img[0][1] t:\",type(generated_images[0][1]))\n","# print(\"train_img[0][0] s:\",generated_images[0][0].size())\n","# print(\"train_img[0][1]  :\",generated_images[0][1])\n","\n","# n_labels = len(generated_images.classes)\n","\n","print(\"train_img type   :\",type(generated_images))\n","print(\"train_img length :\",len(generated_images))\n","# print(\"test_img length :\",len(test_img))\n","print(\"train_img classes:\",generated_images.classes)\n","print(\"train_img[0] type:\",type(generated_images[0]))\n","print(\"train_img[0][0] t:\",type(generated_images[0][0]))\n","print(\"train_img[0][1] t:\",type(generated_images[0][1]))\n","print(\"train_img[0][0] s:\",generated_images[0][0].size())\n","print(\"train_img[0][1]  :\",generated_images[0][1])\n","\n","n_labels = len(generated_images.classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_img type   : <class 'torchvision.datasets.folder.ImageFolder'>\n","train_img length : 23006\n","train_img classes: ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","train_img[0] type: <class 'tuple'>\n","train_img[0][0] t: <class 'torch.Tensor'>\n","train_img[0][1] t: <class 'int'>\n","train_img[0][0] s: torch.Size([3, 32, 32])\n","train_img[0][1]  : 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GmxgXwgOBBQ2"},"source":["# Classification (K Nearest Neighbors)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_-BhkahOYZy-"},"source":["Be sure to run everything before and including \"Loading Data\" part"]},{"cell_type":"markdown","metadata":{"id":"8Gv4Dt3YveG1"},"source":["Image processing"]},{"cell_type":"code","metadata":{"id":"B-6D0CAzvYv8"},"source":["def knn_image_proc(data_img, m = None):\n","  '''\n","  Image flattening and normalization for kNN\n","  Input:\n","    data_img: images and labels\n","  Output:\n","    x_train: processed images (flattened to be vectors and normalized)\n","    y: labels\n","  '''\n","  n_train = len(data_img)\n","\n","  x_raw = []\n","\n","  y = []\n","\n","  for i in range(n_train):\n","    # x_i = train_img[i][0].reshape(-1)\n","    x_i = np.array(data_img[i][0].reshape(-1))\n","    x_raw.append(x_i)\n","    y.append(data_img[i][1])\n","\n","    if i%1000 == 0:\n","      print('Has read ' + str(i) + ' out of ' + str(n_train) + ' images')\n","\n","  # Normalize to zero mean so covariance is just matrix multiplication\n","  if m is None: \n","    m = np.mean(x_raw, axis=0, keepdims=True)\n","  x = x_raw - m \n","\n","  return x, y,  m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trZusXQLvjVz"},"source":["Reduction"]},{"cell_type":"code","metadata":{"id":"WKVEvZZCtjmm"},"source":["def compute_basis(data, n=300):\n","  \"\"\" \n","  Computing basis for image reduction\n","  Inputs:\n","      data: multi-dimensional array of size number of images * number of pixels. Each row is a flatten image.\n","      n: number of modes to be kept\n","  Output:\n","      eigenvectors: basis\n","  \"\"\"\n","  \n","  eigenvectors = None\n","\n","  sig = np.matmul(np.transpose(data),data)\n","  _, eigenvectors = np.linalg.eig(sig)\n","  eigenvectors = eigenvectors[:, range(n)]\n","\n","  return eigenvectors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Id3c1RB2vp3n"},"source":["kNN"]},{"cell_type":"code","metadata":{"id":"KQvR_PCLqg-d"},"source":["# # Self defined kNN function\n","# def knn_predict(eig_train_x, eig_test_x, y_train, y_test, k=1):\n","\n","#   \"\"\"Implement the KNN algorithm. The output should be a vector containing your predictions\"\"\"\n","\n","#   predictions = np.zeros_like(y_test)\n","    \n","#   N, D = eig_train_x.shape\n","#   for i in range(len(y_test)):\n","#     d = np.ones((N,))\n","#     for j in range(N):\n","#       dx = eig_train_x[j,:] - eig_test_x[i,:]\n","#       d[j] = np.linalg.norm(dx)\n","\n","#     x_in = np.argsort(d)\n","#     neb_in = x_in[:k]\n","#     neb_y = y_train[neb_in]\n","\n","#     counts = np.bincount(neb_y)\n","#     predictions[i] = np.argmax(counts)\n","\n","#   return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPc9UwJgSK4e"},"source":["kNN over the fake images"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2lAn79IPdUz","executionInfo":{"status":"ok","timestamp":1618779231898,"user_tz":240,"elapsed":140749,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"d0c28fef-3d8a-4870-d032-d009d0a8374e"},"source":["k = 3 # k nearest neighbors\n","\n","if_POD = True # Do we do POD?\n","\n","# Image flattening and normalization for the original training data set\n","x_train, y_train, mean_train = knn_image_proc(generated_images)\n","\n","# Image reduction\n","if if_POD:\n","  eigenvectors = compute_basis(x_train, n=300)\n","else:\n","  _, n_dim  = x_train.shape\n","  eigenvectors = np.identity(n_dim)\n","\n","x_train_reduced = np.matmul(x_train, eigenvectors)\n","\n","# kNN training\n","neigh = KNeighborsClassifier(n_neighbors = k)\n","neigh.fit(x_train_reduced, y_train)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Has read 0 out of 23006 images\n","Has read 1000 out of 23006 images\n","Has read 2000 out of 23006 images\n","Has read 3000 out of 23006 images\n","Has read 4000 out of 23006 images\n","Has read 5000 out of 23006 images\n","Has read 6000 out of 23006 images\n","Has read 7000 out of 23006 images\n","Has read 8000 out of 23006 images\n","Has read 9000 out of 23006 images\n","Has read 10000 out of 23006 images\n","Has read 11000 out of 23006 images\n","Has read 12000 out of 23006 images\n","Has read 13000 out of 23006 images\n","Has read 14000 out of 23006 images\n","Has read 15000 out of 23006 images\n","Has read 16000 out of 23006 images\n","Has read 17000 out of 23006 images\n","Has read 18000 out of 23006 images\n","Has read 19000 out of 23006 images\n","Has read 20000 out of 23006 images\n","Has read 21000 out of 23006 images\n","Has read 22000 out of 23006 images\n","Has read 23000 out of 23006 images\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(n_neighbors=3)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SdM5HmoB8Bg","executionInfo":{"status":"ok","timestamp":1618779384789,"user_tz":240,"elapsed":152854,"user":{"displayName":"Khoa Dang Nguyen","photoUrl":"","userId":"16010249979492294587"}},"outputId":"b7137624-54d1-41ce-c5e0-4ff0837c5c4e"},"source":["# Image flattening and normalization for the original test data set\n","x_test, y_test, _ = knn_image_proc(test_img, mean_train)\n","\n","x_test_reduced = np.matmul(x_test, eigenvectors)\n","\n","# kNN prediction\n","y_test_kNN = neigh.predict(x_test_reduced)\n","\n","## Evalution\n","accuracy = np.sum(y_test_kNN == np.array(y_test))/y_test_kNN.size\n","print('The accuracy of kNN with generated images is: ', accuracy*100, \"%\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Has read 0 out of 25982 images\n","Has read 1000 out of 25982 images\n","Has read 2000 out of 25982 images\n","Has read 3000 out of 25982 images\n","Has read 4000 out of 25982 images\n","Has read 5000 out of 25982 images\n","Has read 6000 out of 25982 images\n","Has read 7000 out of 25982 images\n","Has read 8000 out of 25982 images\n","Has read 9000 out of 25982 images\n","Has read 10000 out of 25982 images\n","Has read 11000 out of 25982 images\n","Has read 12000 out of 25982 images\n","Has read 13000 out of 25982 images\n","Has read 14000 out of 25982 images\n","Has read 15000 out of 25982 images\n","Has read 16000 out of 25982 images\n","Has read 17000 out of 25982 images\n","Has read 18000 out of 25982 images\n","Has read 19000 out of 25982 images\n","Has read 20000 out of 25982 images\n","Has read 21000 out of 25982 images\n","Has read 22000 out of 25982 images\n","Has read 23000 out of 25982 images\n","Has read 24000 out of 25982 images\n","Has read 25000 out of 25982 images\n","The accuracy of kNN with generated images is:  21.326302825032712 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WB5xjHiZvs3v"},"source":["Visualization"]}]}